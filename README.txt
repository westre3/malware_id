The Machine Learning model that I chose to use was a Decision Tree classifier, as I thought this would work well with the dataset's large number of categorical features. I tuned the Decision Tree's hyperparameters using a similar method to the original paper. First, I undersampled the dataset to get an equal number of malware samples and goodware samples. Next, I removed 30% of these samples to be test data. I then used a grid search along with 5-fold cross-validation to choose the best hyperparameters. The results in results.txt were computed by running the best model found by the grid search on the test data. The actual predictions for each sample in the test set are recorded in classifications.txt. For convenience, I also produce a dotfile named tree_visualization.dot containing the best model's actual decision tree. This dotfile can be visualized using a tool such as the one at http://webgraphviz.com/.

To execute the code, simply run the shell script run.sh
